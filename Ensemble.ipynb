{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:31:28.877247Z",
     "iopub.status.busy": "2024-09-24T05:31:28.876942Z",
     "iopub.status.idle": "2024-09-24T05:31:44.539077Z",
     "shell.execute_reply": "2024-09-24T05:31:44.537718Z",
     "shell.execute_reply.started": "2024-09-24T05:31:28.877216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
      "Building wheels for collected packages: efficientnet_pytorch\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=75c7e096bf5372632c0794f5dedd7a9883f5225b1677869404ad8f1393fd4653\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
      "Successfully built efficientnet_pytorch\n",
      "Installing collected packages: efficientnet_pytorch\n",
      "Successfully installed efficientnet_pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (2.2.5)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (11.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (2.7.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (0.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from torch) (75.6.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading torchvision-0.22.0-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.6/1.7 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp313-cp313-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.1 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.2/11.1 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.1 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/41.0 MB 6.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/41.0 MB 6.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 4.2/41.0 MB 7.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.8/41.0 MB 7.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.6/41.0 MB 6.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.3/41.0 MB 6.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.4/41.0 MB 5.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.4/41.0 MB 5.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 11.0/41.0 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 12.6/41.0 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.9/41.0 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 15.5/41.0 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 17.3/41.0 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.9/41.0 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 20.4/41.0 MB 6.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 21.5/41.0 MB 6.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.5/41.0 MB 6.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.9/41.0 MB 6.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 25.2/41.0 MB 6.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.7/41.0 MB 6.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.3/41.0 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 29.1/41.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.6/41.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.1/41.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 30.4/41.0 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.2/41.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.2/41.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.6/41.0 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.9/41.0 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/41.0 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.0/41.0 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.3/41.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, scipy, joblib, scikit-learn, torchvision, torchaudio, sklearn-compat, imbalanced-learn\n",
      "\n",
      "   ---------------------------------------- 0/9 [tqdm]\n",
      "   ---------------------------------------- 0/9 [tqdm]\n",
      "   ---------------------------------------- 0/9 [tqdm]\n",
      "   ---------------------------------------- 0/9 [tqdm]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   -------- ------------------------------- 2/9 [scipy]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ------------- -------------------------- 3/9 [joblib]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ----------------- ---------------------- 4/9 [scikit-learn]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   ---------------------- ----------------- 5/9 [torchvision]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   -------------------------- ------------- 6/9 [torchaudio]\n",
      "   ------------------------------- -------- 7/9 [sklearn-compat]\n",
      "   ------------------------------- -------- 7/9 [sklearn-compat]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ----------------------------------- ---- 8/9 [imbalanced-learn]\n",
      "   ---------------------------------------- 9/9 [imbalanced-learn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 joblib-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 sklearn-compat-0.1.3 threadpoolctl-3.6.0 torchaudio-2.7.0 torchvision-0.22.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy tqdm pillow torch torchvision torchaudio scikit-learn imbalanced-learn efficientnet_pytorch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:16.684321Z",
     "iopub.status.busy": "2024-09-24T05:32:16.683402Z",
     "iopub.status.idle": "2024-09-24T05:32:22.081078Z",
     "shell.execute_reply": "2024-09-24T05:32:22.080256Z",
     "shell.execute_reply.started": "2024-09-24T05:32:16.684277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:23.148702Z",
     "iopub.status.busy": "2024-09-24T05:32:23.148231Z",
     "iopub.status.idle": "2024-09-24T05:32:23.155353Z",
     "shell.execute_reply": "2024-09-24T05:32:23.154316Z",
     "shell.execute_reply.started": "2024-09-24T05:32:23.148667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Custom Dataset\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:23.948218Z",
     "iopub.status.busy": "2024-09-24T05:32:23.947794Z",
     "iopub.status.idle": "2024-09-24T05:32:23.954862Z",
     "shell.execute_reply": "2024-09-24T05:32:23.954069Z",
     "shell.execute_reply.started": "2024-09-24T05:32:23.948178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Loading and preprocessing the data\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    classes = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        for split in ['train', 'test']:\n",
    "            class_dir = os.path.join(data_dir, split, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                X.append(img)\n",
    "                y.append(i)\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:24.323550Z",
     "iopub.status.busy": "2024-09-24T05:32:24.322682Z",
     "iopub.status.idle": "2024-09-24T05:32:24.330489Z",
     "shell.execute_reply": "2024-09-24T05:32:24.329524Z",
     "shell.execute_reply.started": "2024-09-24T05:32:24.323512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from PIL import Image\n",
    "\n",
    "def apply_adasyn(X, y):\n",
    "    # Convert PIL Images to numpy arrays\n",
    "    X_arrays = [np.array(img) for img in X]\n",
    "    \n",
    "    # Get the shape of the images\n",
    "    img_shape = X_arrays[0].shape\n",
    "    \n",
    "    # Reshape the arrays to 2D for ADASYN\n",
    "    X_reshaped = np.array([x.flatten() for x in X_arrays])\n",
    "    \n",
    "    # Apply ADASYN\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X_resampled, y_resampled = adasyn.fit_resample(X_reshaped, y)\n",
    "    \n",
    "    # Reshape back to original image shape\n",
    "    X_balanced = [x.reshape(img_shape) for x in X_resampled]\n",
    "    \n",
    "    # Convert back to PIL Images\n",
    "    X_balanced = [Image.fromarray(x.astype('uint8')) for x in X_balanced]\n",
    "    \n",
    "    return X_balanced, y_resampled\n",
    "\n",
    "# The rest of the code remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def apply_smote(X, y):\n",
    "    # Convert PIL Images to numpy arrays\n",
    "    X_arrays = [np.array(img) for img in X]\n",
    "    \n",
    "    # Get the shape of the images\n",
    "    img_shape = X_arrays[0].shape\n",
    "    \n",
    "    # Reshape the arrays to 2D for SMOTE\n",
    "    X_reshaped = np.array([x.flatten() for x in X_arrays])\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_reshaped, y)\n",
    "    \n",
    "    # Reshape back to original image shape\n",
    "    X_balanced = [x.reshape(img_shape) for x in X_resampled]\n",
    "    \n",
    "    # Convert back to PIL Images\n",
    "    X_balanced = [Image.fromarray(x.astype('uint8')) for x in X_balanced]\n",
    "    \n",
    "    return X_balanced, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:24.763846Z",
     "iopub.status.busy": "2024-09-24T05:32:24.762936Z",
     "iopub.status.idle": "2024-09-24T05:32:24.769323Z",
     "shell.execute_reply": "2024-09-24T05:32:24.768304Z",
     "shell.execute_reply.started": "2024-09-24T05:32:24.763780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. Splitting the balanced data\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, stratify=y_train, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:35:42.043989Z",
     "iopub.status.busy": "2024-09-24T05:35:42.043312Z",
     "iopub.status.idle": "2024-09-24T05:35:42.058138Z",
     "shell.execute_reply": "2024-09-24T05:35:42.057042Z",
     "shell.execute_reply.started": "2024-09-24T05:35:42.043943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Creating the ensemble model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        # Load pre-trained VGG16\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        self.vgg16_features = nn.Sequential(*list(self.vgg16.features.children())[:-1])\n",
    "        \n",
    "        # Load pre-trained EfficientNet-B2\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "        self.efficientnet._fc = nn.Identity()  # Remove the final fully connected layer\n",
    "        \n",
    "        # Adaptive pooling to ensure consistent spatial dimensions\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Combined feature processing\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * 1920)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 1920, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # VGG16 feature extraction\n",
    "        vgg_features = self.vgg16_features(x)\n",
    "        vgg_features = self.adaptive_pool(vgg_features)\n",
    "        \n",
    "        # EfficientNet-B2 feature extraction\n",
    "        efficientnet_features = self.efficientnet.extract_features(x)\n",
    "        efficientnet_features = self.adaptive_pool(efficientnet_features)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((vgg_features, efficientnet_features), dim=1)\n",
    "        \n",
    "        # Process combined features\n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Replace the create_model function with this:\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:25.623232Z",
     "iopub.status.busy": "2024-09-24T05:32:25.622833Z",
     "iopub.status.idle": "2024-09-24T05:32:25.636616Z",
     "shell.execute_reply": "2024-09-24T05:32:25.635674Z",
     "shell.execute_reply.started": "2024-09-24T05:32:25.623195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, device='cuda'):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:26.043472Z",
     "iopub.status.busy": "2024-09-24T05:32:26.042706Z",
     "iopub.status.idle": "2024-09-24T05:32:26.050747Z",
     "shell.execute_reply": "2024-09-24T05:32:26.049797Z",
     "shell.execute_reply.started": "2024-09-24T05:32:26.043429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 7. Testing function\n",
    "def test_model(model, test_loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = test_correct / test_total\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:27.483283Z",
     "iopub.status.busy": "2024-09-24T05:32:27.482516Z",
     "iopub.status.idle": "2024-09-24T05:32:27.520866Z",
     "shell.execute_reply": "2024-09-24T05:32:27.519061Z",
     "shell.execute_reply.started": "2024-09-24T05:32:27.483245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\dell\\OneDrive\\Desktop\\alzheimers-disease-detection-main\\alzheimers-disease-detection-main\\Combined Dataset\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:32:29.198062Z",
     "iopub.status.busy": "2024-09-24T05:32:29.197435Z",
     "iopub.status.idle": "2024-09-24T05:33:16.672090Z",
     "shell.execute_reply": "2024-09-24T05:33:16.671222Z",
     "shell.execute_reply.started": "2024-09-24T05:32:29.198023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "X, y = load_and_preprocess_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:33:16.674141Z",
     "iopub.status.busy": "2024-09-24T05:33:16.673793Z",
     "iopub.status.idle": "2024-09-24T05:33:16.680935Z",
     "shell.execute_reply": "2024-09-24T05:33:16.679967Z",
     "shell.execute_reply.started": "2024-09-24T05:33:16.674108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:33:16.683306Z",
     "iopub.status.busy": "2024-09-24T05:33:16.682252Z",
     "iopub.status.idle": "2024-09-24T05:33:16.692024Z",
     "shell.execute_reply": "2024-09-24T05:33:16.691151Z",
     "shell.execute_reply.started": "2024-09-24T05:33:16.683249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:33:16.695193Z",
     "iopub.status.busy": "2024-09-24T05:33:16.694400Z",
     "iopub.status.idle": "2024-09-24T05:34:19.884772Z",
     "shell.execute_reply": "2024-09-24T05:34:19.883755Z",
     "shell.execute_reply.started": "2024-09-24T05:33:16.695139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply ADASYN\n",
    "X_balanced, y_balanced = apply_smote(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:34:19.886620Z",
     "iopub.status.busy": "2024-09-24T05:34:19.886242Z",
     "iopub.status.idle": "2024-09-24T05:34:19.892596Z",
     "shell.execute_reply": "2024-09-24T05:34:19.891736Z",
     "shell.execute_reply.started": "2024-09-24T05:34:19.886576Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4324"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:34:19.894099Z",
     "iopub.status.busy": "2024-09-24T05:34:19.893768Z",
     "iopub.status.idle": "2024-09-24T05:34:19.906606Z",
     "shell.execute_reply": "2024-09-24T05:34:19.905712Z",
     "shell.execute_reply.started": "2024-09-24T05:34:19.894063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4324"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:34:19.908076Z",
     "iopub.status.busy": "2024-09-24T05:34:19.907776Z",
     "iopub.status.idle": "2024-09-24T05:34:19.931113Z",
     "shell.execute_reply": "2024-09-24T05:34:19.930266Z",
     "shell.execute_reply.started": "2024-09-24T05:34:19.908040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_balanced, y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:34:19.932494Z",
     "iopub.status.busy": "2024-09-24T05:34:19.932223Z",
     "iopub.status.idle": "2024-09-24T05:34:19.937645Z",
     "shell.execute_reply": "2024-09-24T05:34:19.936715Z",
     "shell.execute_reply.started": "2024-09-24T05:34:19.932464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:34:19.939203Z",
     "iopub.status.busy": "2024-09-24T05:34:19.938847Z",
     "iopub.status.idle": "2024-09-24T05:34:19.947722Z",
     "shell.execute_reply": "2024-09-24T05:34:19.946947Z",
     "shell.execute_reply.started": "2024-09-24T05:34:19.939163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AlzheimerDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = AlzheimerDataset(X_val, y_val, transform=transform)\n",
    "test_dataset = AlzheimerDataset(X_test, y_test, transform=transform)\n",
    "    \n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:35:55.052681Z",
     "iopub.status.busy": "2024-09-24T05:35:55.052309Z",
     "iopub.status.idle": "2024-09-24T05:35:56.975334Z",
     "shell.execute_reply": "2024-09-24T05:35:56.974520Z",
     "shell.execute_reply.started": "2024-09-24T05:35:55.052645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dell\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:36:00.822779Z",
     "iopub.status.busy": "2024-09-24T05:36:00.822408Z",
     "iopub.status.idle": "2024-09-24T05:36:00.830309Z",
     "shell.execute_reply": "2024-09-24T05:36:00.829231Z",
     "shell.execute_reply.started": "2024-09-24T05:36:00.822744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T05:36:07.003906Z",
     "iopub.status.busy": "2024-09-24T05:36:07.003014Z",
     "iopub.status.idle": "2024-09-24T06:38:14.875119Z",
     "shell.execute_reply": "2024-09-24T06:38:14.873517Z",
     "shell.execute_reply.started": "2024-09-24T05:36:07.003868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T06:38:14.877699Z",
     "iopub.status.busy": "2024-09-24T06:38:14.877352Z",
     "iopub.status.idle": "2024-09-24T06:38:28.471928Z",
     "shell.execute_reply": "2024-09-24T06:38:28.470720Z",
     "shell.execute_reply.started": "2024-09-24T06:38:14.877661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/4122861454.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0753, Test Acc: 0.9742\n"
     ]
    }
   ],
   "source": [
    "# Load best model and test\n",
    "best_model = create_model().to(device)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_model(best_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 457093,
     "sourceId": 861496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
